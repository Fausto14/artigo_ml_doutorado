{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 1,
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR BIBLIOTECAS UTILIZADAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 2,
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Classe para processar o dataset\n",
    "    Obs: o dataset tem que ser para problemas de classificacao e nele tem que conter uma coluna Class\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../Util'))\n",
    "from dados import ProcessarDados"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANDO DATASET\n",
    "\n",
    "dataset = ProcessarDados('../dataset/norm_bin_10_FEATURES_M17_CM6b_TH199.csv')"
=======
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASM</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>IDM</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Homogeneity</th>\n",
       "      <th>Sum Mean</th>\n",
       "      <th>Maximum Probability</th>\n",
       "      <th>Dissimilarity</th>\n",
       "      <th>Difference mean</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.335251</td>\n",
       "      <td>0.129558</td>\n",
       "      <td>0.075368</td>\n",
       "      <td>-0.217948</td>\n",
       "      <td>0.085027</td>\n",
       "      <td>-0.416246</td>\n",
       "      <td>0.381153</td>\n",
       "      <td>0.080254</td>\n",
       "      <td>-0.883902</td>\n",
       "      <td>-0.456044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.885760</td>\n",
       "      <td>0.386018</td>\n",
       "      <td>-0.923351</td>\n",
       "      <td>1.009975</td>\n",
       "      <td>-0.894400</td>\n",
       "      <td>0.801297</td>\n",
       "      <td>-0.797996</td>\n",
       "      <td>0.447709</td>\n",
       "      <td>-0.880798</td>\n",
       "      <td>0.776265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123592</td>\n",
       "      <td>-0.542303</td>\n",
       "      <td>0.940650</td>\n",
       "      <td>-1.090059</td>\n",
       "      <td>0.935049</td>\n",
       "      <td>-1.065749</td>\n",
       "      <td>1.047057</td>\n",
       "      <td>-0.579544</td>\n",
       "      <td>-0.525477</td>\n",
       "      <td>-1.054323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.026201</td>\n",
       "      <td>-0.734210</td>\n",
       "      <td>0.878630</td>\n",
       "      <td>-0.956559</td>\n",
       "      <td>0.888416</td>\n",
       "      <td>-0.941286</td>\n",
       "      <td>0.968096</td>\n",
       "      <td>-0.742946</td>\n",
       "      <td>-0.607713</td>\n",
       "      <td>-0.884183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.335251</td>\n",
       "      <td>0.129558</td>\n",
       "      <td>0.075368</td>\n",
       "      <td>-0.217948</td>\n",
       "      <td>0.085027</td>\n",
       "      <td>-0.416246</td>\n",
       "      <td>0.381153</td>\n",
       "      <td>0.080254</td>\n",
       "      <td>-0.883902</td>\n",
       "      <td>-0.456044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.061220</td>\n",
       "      <td>-0.198626</td>\n",
       "      <td>0.166651</td>\n",
       "      <td>-0.151004</td>\n",
       "      <td>0.158793</td>\n",
       "      <td>-0.181947</td>\n",
       "      <td>0.131110</td>\n",
       "      <td>-0.161593</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>-0.217375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1.809695</td>\n",
       "      <td>-1.328606</td>\n",
       "      <td>1.597141</td>\n",
       "      <td>-1.775954</td>\n",
       "      <td>1.601985</td>\n",
       "      <td>-1.498905</td>\n",
       "      <td>1.583991</td>\n",
       "      <td>-1.356058</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>-1.364799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1.757473</td>\n",
       "      <td>-1.377717</td>\n",
       "      <td>1.566812</td>\n",
       "      <td>-1.693196</td>\n",
       "      <td>1.574930</td>\n",
       "      <td>-1.444270</td>\n",
       "      <td>1.544510</td>\n",
       "      <td>-1.403062</td>\n",
       "      <td>0.479973</td>\n",
       "      <td>-1.297651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1.924871</td>\n",
       "      <td>-1.549759</td>\n",
       "      <td>1.722244</td>\n",
       "      <td>-1.875724</td>\n",
       "      <td>1.733206</td>\n",
       "      <td>-1.548071</td>\n",
       "      <td>1.670848</td>\n",
       "      <td>-1.579326</td>\n",
       "      <td>-0.109643</td>\n",
       "      <td>-1.377026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1.381084</td>\n",
       "      <td>-0.835457</td>\n",
       "      <td>1.231883</td>\n",
       "      <td>-1.390763</td>\n",
       "      <td>1.223271</td>\n",
       "      <td>-1.245981</td>\n",
       "      <td>1.252355</td>\n",
       "      <td>-0.860455</td>\n",
       "      <td>0.524970</td>\n",
       "      <td>-1.196782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASM  Contrast       IDM   Entropy  Homogeneity  Sum Mean  \\\n",
       "0    0.335251  0.129558  0.075368 -0.217948     0.085027 -0.416246   \n",
       "1   -0.885760  0.386018 -0.923351  1.009975    -0.894400  0.801297   \n",
       "2    1.123592 -0.542303  0.940650 -1.090059     0.935049 -1.065749   \n",
       "3    1.026201 -0.734210  0.878630 -0.956559     0.888416 -0.941286   \n",
       "4    0.335251  0.129558  0.075368 -0.217948     0.085027 -0.416246   \n",
       "..        ...       ...       ...       ...          ...       ...   \n",
       "595  0.061220 -0.198626  0.166651 -0.151004     0.158793 -0.181947   \n",
       "596  1.809695 -1.328606  1.597141 -1.775954     1.601985 -1.498905   \n",
       "597  1.757473 -1.377717  1.566812 -1.693196     1.574930 -1.444270   \n",
       "598  1.924871 -1.549759  1.722244 -1.875724     1.733206 -1.548071   \n",
       "599  1.381084 -0.835457  1.231883 -1.390763     1.223271 -1.245981   \n",
       "\n",
       "     Maximum Probability  Dissimilarity  Difference mean  Autocorrelation  \\\n",
       "0               0.381153       0.080254        -0.883902        -0.456044   \n",
       "1              -0.797996       0.447709        -0.880798         0.776265   \n",
       "2               1.047057      -0.579544        -0.525477        -1.054323   \n",
       "3               0.968096      -0.742946        -0.607713        -0.884183   \n",
       "4               0.381153       0.080254        -0.883902        -0.456044   \n",
       "..                   ...            ...              ...              ...   \n",
       "595             0.131110      -0.161593        -0.010339        -0.217375   \n",
       "596             1.583991      -1.356058         0.045519        -1.364799   \n",
       "597             1.544510      -1.403062         0.479973        -1.297651   \n",
       "598             1.670848      -1.579326        -0.109643        -1.377026   \n",
       "599             1.252355      -0.860455         0.524970        -1.196782   \n",
       "\n",
       "     Class  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "595      0  \n",
       "596      0  \n",
       "597      0  \n",
       "598      0  \n",
       "599      0  \n",
       "\n",
       "[600 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTANDO DATASET\n",
    "\n",
    "dataset = ProcessarDados('../dataset/norm_bin_10_FEATURES_M17_CM6b_TH199.csv')\n",
    "dataset.data"
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 4,
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcção que treina e testa o modelo armazenando as métricas\n",
    "# retorna um dicionário cotendo os valores das métricas de cada rodada\n",
    "\n",
    "def treinamento_teste(epocas = 10, k_folds = 5, exibir_matriz_confusao=False, exibir_metricas=False):\n",
    "    \n",
    "    #array para armazenar as das métricas de cada rodada\n",
    "    resultados_accuracy = []\n",
    "    resultados_precision = []\n",
    "    resultados_recall = []\n",
    "    resultados_f1 = []\n",
    "    #resultados_parametros = []\n",
    "    \n",
    "    #dicionário das métricas\n",
    "    resultados_gerais = {}\n",
    "\n",
    "    for i in range(epocas):\n",
    "        #SEPARAR DADOS DE TREINO E TESTE MANTENDO A MESMA PROPORÇÃO  (80% E 20%)\n",
    "        \n",
    "        X_treino, X_teste, y_treino, y_teste = dataset.holdout(0.2)\n",
    "        \n",
    "        #ALTERANDO DIMENSÃO DE Y PARA D=1\n",
    "\n",
    "        y_treino = y_treino.reshape(480,)\n",
    "        y_teste = y_teste.reshape(120,)\n",
    "                \n",
    "        #ADICIONAR ATRIBUTOS IGUAIS A 1 EM X0\n",
    "\n",
    "        X_treino = np.c_[np.ones(X_treino.shape[0]), X_treino]\n",
    "\n",
    "        X_teste = np.c_[np.ones(X_teste.shape[0]), X_teste]\n",
    "        \n",
    "        #DEFINIR FUNCAO LOGISTICA (SIGMOID) PARA PREVER A PROBABILIDADE \n",
    "\n",
    "        def sigmoid(w,X):\n",
    "            z = np.dot(X,w)\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        \n",
    "        #DEFINIR FUNCAO PARA CLASSIFICAR\n",
    "        \n",
    "        def classificar(y, limiar=0.5):\n",
    "            return (y > limiar)*1\n",
    "\n",
    "        #DEFINIR FUNCAO CUSTO UTILIZANDO ENTROPIA CRUZADA\n",
    "\n",
    "        def entropiaCruzada(previsto,y):\n",
    "            return (-y * np.log(previsto) - (1 - y) * np.log(1 - previsto)).mean()\n",
    "        \n",
    "        #DEFINIR FUNCAO GRADIENTE DESCENDENTE PARA ATUALIZAR OS PARAMÊTROS w\n",
    "\n",
    "        def gradienteDescendente(w, X, y, alpha):\n",
    "            previsto = sigmoid(w,X)\n",
    "            erro = previsto - y\n",
    "            gradiente = np.dot(X.T, erro) / len(X)\n",
    "            w -= alpha*gradiente\n",
    "\n",
    "        #INICIALIZAR W (THETA) DE FORMA RANDOMICA e OTIMIZAR PARÂMETROS \n",
    "\n",
    "        w = np.random.rand(X_treino.shape[1])\n",
    "        \n",
<<<<<<< HEAD
    "        for i in range(3000):\n",
    "            custo = entropiaCruzada(sigmoid(w,X_treino),y_treino)\n",
    "            \n",
    "            gradienteDescendente(w,X_treino,y_treino,0.01)\n",
    "        \n",
    "        #TREINANDO O MODELO\n",
    "        \n",
=======
    "        for i in range(7000):\n",
    "            custo = entropiaCruzada(sigmoid(w,X_treino),y_treino)\n",
    "            \n",
    "            gradienteDescendente(w,X_treino,y_treino,0.1)\n",
    "\n",
    "\n",
    "        #TREINANDO O MODELO\n",
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
    "        classificados = classificar(sigmoid(w,X_treino))\n",
    "        \n",
    "        #TESTANDO O MODELO\n",
    "        \n",
    "        y_pred = classificar(sigmoid(w,X_teste))\n",
    "        \n",
    "        if exibir_matriz_confusao:\n",
    "            print(confusion_matrix(y_teste, y_pred))\n",
    "\n",
    "        # calculado as metricas\n",
    "        accuracy = metrics.accuracy_score(y_teste, y_pred)\n",
    "        precision = metrics.precision_score(y_teste, y_pred)\n",
    "        recall = metrics.recall_score(y_teste, y_pred)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "\n",
    "        # armazenando as métricas\n",
    "        resultados_accuracy.append(accuracy)\n",
    "        resultados_precision.append(precision)\n",
    "        resultados_recall.append(recall)\n",
    "        resultados_f1.append(f1_score)\n",
    "\n",
    "\n",
    "        if exibir_metricas:\n",
    "            print(\"Rodada: #\",i)\n",
    "            print(\"Accuracy:\",accuracy)\n",
    "            print(\"Precision:\",precision)\n",
    "            print(\"Recall:\",recall)\n",
    "            print(\"F1-Score:\",f1_score)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            \n",
    "    resultados_gerais['accuracy'] = resultados_accuracy\n",
    "    resultados_gerais['precision'] = resultados_precision\n",
    "    resultados_gerais['recall'] = resultados_recall\n",
    "    resultados_gerais['f1'] = resultados_f1\n",
    "    \n",
    "    return resultados_gerais"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 5,
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   "metadata": {},
   "outputs": [],
   "source": [
    "#TABELA COM RESULTADO DAS MÉTRICAS\n",
    "\n",
    "def tabelaMetricas(nome_modelo, dict_metricas, rodadas=False):\n",
    "    print (\"============================================== \"+nome_modelo+\" =================================================\")\n",
    "    print (\"=================================== TABELA DE MÉTRICAS DO MODELO ===================================\")\n",
    "    \n",
    "    if(rodadas==False):\n",
    "        print (\"\\t Accuracy \\t|\\t Precision \\t|\\t Recall \\t|\\t F1-Score\")\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['accuracy'], axis=0), np.std(dict_metricas['accuracy'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['precision'], axis=0), np.std(dict_metricas['precision'], axis=0)),end='    ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['recall'], axis=0), np.std(dict_metricas['recall'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['f1'], axis=0), np.std(dict_metricas['f1'], axis=0)))\n",
    "        print (\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 6,
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================== REGRESSÃO LOGÍSTICA =================================================\n",
      "=================================== TABELA DE MÉTRICAS DO MODELO ===================================\n",
      "\t Accuracy \t|\t Precision \t|\t Recall \t|\t F1-Score\n",
<<<<<<< HEAD
      "      0.89 +- 0.02             0.90 +- 0.02          0.95 +- 0.02             0.93 +- 0.02\n",
=======
      "      0.90 +- 0.02             0.92 +- 0.03          0.94 +- 0.02             0.93 +- 0.02\n",
>>>>>>> b9e8945f94505f8daf6d20fe10dfb963ecfb4ee4
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#DEFININDO OS PARÂMETROS\n",
    "\n",
    "epocas = 50\n",
    "k_folds = 5\n",
    "exibir_matriz_confusao = False\n",
    "exibir_metricas = False\n",
    "\n",
    "# TREINANDO O MODELO E OBTENDO AS MÉTRICAS\n",
    "\n",
    "dict_metricas = treinamento_teste(epocas, k_folds, exibir_matriz_confusao, exibir_metricas)\n",
    "tabelaMetricas('REGRESSÃO LOGÍSTICA',dict_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
