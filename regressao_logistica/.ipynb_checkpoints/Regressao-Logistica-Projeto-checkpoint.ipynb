{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR BIBLIOTECAS UTILIZADAS\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "from numpy import unravel_index\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Classe para processar o dataset\n",
    "    Obs: o dataset tem que ser para problemas de classificacao e nele tem que conter uma coluna Class\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../Util'))\n",
    "from dados import ProcessarDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANDO DATASET\n",
    "dataset = ProcessarDados('../dataset/norm_bin_10_FEATURES_M17_CM6b_TH199.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINIR FUNCAO LOGISTICA (SIGMOID) PARA PREVER A PROBABILIDADE \n",
    "def sigmoid(w,X):\n",
    "    z = np.dot(X,w)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "#DEFINIR FUNCAO PARA CLASSIFICAR\n",
    "def classificar(y, limiar=0.5):\n",
    "    return (y > limiar)*1\n",
    "\n",
    "#DEFINIR FUNCAO CUSTO UTILIZANDO ENTROPIA CRUZADA\n",
    "def entropiaCruzada(previsto,y):\n",
    "    return (-y * np.log(previsto) - (1 - y) * np.log(1 - previsto)).mean()\n",
    "\n",
    "#DEFINIR FUNCAO GRADIENTE DESCENDENTE PARA ATUALIZAR OS PARAMÊTROS w\n",
    "def gradienteDescendente(w, X, y, alpha):\n",
    "    previsto = sigmoid(w,X)\n",
    "    erro = previsto - y\n",
    "    gradiente = np.dot(X.T, erro) / len(X)\n",
    "    w -= alpha*gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcção que treina e testa o modelo armazenando as métricas\n",
    "# retorna um dicionário cotendo os valores das métricas de cada rodada\n",
    "\n",
    "def treinamento_teste(epocas = 10, k_folds = 5, exibir_matriz_confusao=False, exibir_metricas=False):\n",
    "    \n",
    "    #array para armazenar as das métricas de cada rodada\n",
    "    resultados_accuracy = []\n",
    "    resultados_precision = []\n",
    "    resultados_recall = []\n",
    "    resultados_specificity = [] # taxa de verdadeiros negativos ou especificidade\n",
    "    resultados_f2 = []\n",
    "    resultados_parametros = []\n",
    "    \n",
    "    #dicionário das métricas\n",
    "    resultados_gerais = {}\n",
    "\n",
    "    for i in range(epocas):\n",
    "        #SEPARAR DADOS DE TREINO E TESTE MANTENDO A MESMA PROPORÇÃO  (80% E 20%)\n",
    "        seed = i\n",
    "        X_treino, X_teste, y_treino, y_teste = dataset.holdout(0.2, seed)\n",
    "        \n",
    "        #ALTERANDO DIMENSÃO DE Y PARA D=1\n",
    "        y_treino = y_treino.reshape(480,)\n",
    "        y_teste = y_teste.reshape(120,)\n",
    "        \n",
    "        #ADICIONAR ATRIBUTOS IGUAIS A 1 EM X0\n",
    "        X_treino = np.c_[np.ones(X_treino.shape[0]), X_treino]\n",
    "        X_teste = np.c_[np.ones(X_teste.shape[0]), X_teste]\n",
    "        \n",
    "        array_w = {}\n",
    "        array_alpha = {}\n",
    "        array_acc = {}\n",
    "        # rodando o grid search\n",
    "        for index_g, grid_alpha in enumerate(np.logspace(-3,0,25)):\n",
    "            # rodando o k-folds\n",
    "            for index_k, k in enumerate(dataset.kfolds(X_treino, y_treino, k_folds, seed)):\n",
    "                kx_treino, ky_treino, kx_teste, ky_teste = k\n",
    "\n",
    "                #INICIALIZAR W (THETA) DE FORMA RANDOMICA e OTIMIZAR PARÂMETROS \n",
    "                w = np.random.rand(kx_treino.shape[1])\n",
    "\n",
    "                # otimização do W\n",
    "                for x in range(max_iter):\n",
    "                    custo = entropiaCruzada(sigmoid(w,kx_treino),ky_treino)\n",
    "                    gradienteDescendente(w,kx_treino,ky_treino,grid_alpha)\n",
    "\n",
    "                    \n",
    "                #TESTANDO O MODELO\n",
    "                ky_pred = classificar(sigmoid(w,kx_teste))\n",
    "                k_accuracy = metrics.accuracy_score(ky_teste, ky_pred)\n",
    "\n",
    "                array_w[index_g,index_k] = w\n",
    "                array_alpha[index_g,index_k] = grid_alpha\n",
    "                array_acc[index_g,index_k] = k_accuracy\n",
    "            \n",
    "        # acessando o melhor W pela acurácia\n",
    "        pos_best_lin = max(array_acc.items(), key=operator.itemgetter(1))[0][0]\n",
    "        pos_best_col = max(array_acc.items(), key=operator.itemgetter(1))[0][1]\n",
    "        \n",
    "        best_w = array_w[pos_best_lin,pos_best_col]\n",
    "        \n",
    "        \n",
    "        #TESTE FINAL O MODELO COM O MELHOR W APÓS O KFOLD\n",
    "        y_pred = classificar(sigmoid(best_w, X_teste))\n",
    "            \n",
    "        \n",
    "        cm  = confusion_matrix(y_teste, y_pred)\n",
    "        if exibir_matriz_confusao:\n",
    "            print(cm)\n",
    "\n",
    "        # calculado as metricas\n",
    "        accuracy = metrics.accuracy_score(y_teste, y_pred)\n",
    "        precision = metrics.precision_score(y_teste, y_pred)\n",
    "        recall = metrics.recall_score(y_teste, y_pred)\n",
    "        # f2-score\n",
    "        # Fbeta = ((1 + beta^2) * Precision * Recall) / (beta^2 * Precision + Recall)\n",
    "        beta = 0.5\n",
    "        f2_score = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        \n",
    "\n",
    "        # armazenando as métricas\n",
    "        resultados_accuracy.append(accuracy)\n",
    "        resultados_precision.append(precision)\n",
    "        resultados_recall.append(recall)\n",
    "        resultados_specificity.append(specificity)\n",
    "        resultados_f2.append(f2_score)\n",
    "\n",
    "\n",
    "        best_parametros = {'alpha' : array_alpha[pos_best_lin,pos_best_col]};\n",
    "        resultados_parametros.append(best_parametros)\n",
    "        \n",
    "        if exibir_metricas:\n",
    "            print(\"Rodada: #\",i)\n",
    "            print(best_parametros)\n",
    "            print(\"Accuracy:\",accuracy)\n",
    "            print(\"Precision:\",precision)\n",
    "            print(\"Recall:\",recall)\n",
    "            print(\"Specificity:\",specificity)\n",
    "            print(\"f2-Score:\",f2_score)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            \n",
    "    resultados_gerais['accuracy'] = resultados_accuracy\n",
    "    resultados_gerais['precision'] = resultados_precision\n",
    "    resultados_gerais['recall'] = resultados_recall\n",
    "    resultados_gerais['specificity'] = resultados_specificity\n",
    "    resultados_gerais['f2'] = resultados_f2\n",
    "    resultados_gerais['params'] = resultados_parametros\n",
    "    \n",
    "    return resultados_gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabelaMetricas(nome_modelo, dict_metricas, rodadas=False, salvarResultados=True):\n",
    "        \n",
    "    print (\"============================================== \"+nome_modelo+\" =================================================\")\n",
    "    print (\"=================================== TABELA DE MÉTRICAS DO MODELO ===================================\")\n",
    "    \n",
    "    if(rodadas==False):\n",
    "        print (\"\\t Accuracy \\t|\\t Precision \\t|\\t Recall \\t|\\tSpecificity \\t|\\t fb-Score\")\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['accuracy'], axis=0), np.std(dict_metricas['accuracy'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['precision'], axis=0), np.std(dict_metricas['precision'], axis=0)),end='    ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['recall'], axis=0), np.std(dict_metricas['recall'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['specificity'], axis=0), np.std(dict_metricas['specificity'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['f2'], axis=0), np.std(dict_metricas['f2'], axis=0)))\n",
    "        print (\"====================================================================================================\")\n",
    "        \n",
    "    if(salvarResultados):\n",
    "        # save to npy file\n",
    "        np.save('../resultados/resultados_'+nome_modelo+'.npy', dict_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  4]\n",
      " [ 7 85]]\n",
      "Rodada: # 0\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9550561797752809\n",
      "Recall: 0.9239130434782609\n",
      "Specificity: 0.8571428571428571\n",
      "f2-Score: 0.9486607142857142\n",
      "\n",
      "\n",
      "[[16 17]\n",
      " [ 2 85]]\n",
      "Rodada: # 1\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8416666666666667\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.9770114942528736\n",
      "Specificity: 0.48484848484848486\n",
      "f2-Score: 0.8585858585858588\n",
      "\n",
      "\n",
      "[[16  6]\n",
      " [ 9 89]]\n",
      "Rodada: # 2\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.9368421052631579\n",
      "Recall: 0.9081632653061225\n",
      "Specificity: 0.7272727272727273\n",
      "f2-Score: 0.9309623430962345\n",
      "\n",
      "\n",
      "[[24  8]\n",
      " [ 4 84]]\n",
      "Rodada: # 3\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9130434782608695\n",
      "Recall: 0.9545454545454546\n",
      "Specificity: 0.75\n",
      "f2-Score: 0.9210526315789473\n",
      "\n",
      "\n",
      "[[24  4]\n",
      " [ 4 88]]\n",
      "Rodada: # 4\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9565217391304348\n",
      "Recall: 0.9565217391304348\n",
      "Specificity: 0.8571428571428571\n",
      "f2-Score: 0.9565217391304348\n",
      "\n",
      "\n",
      "[[14 18]\n",
      " [ 2 86]]\n",
      "Rodada: # 5\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8333333333333334\n",
      "Precision: 0.8269230769230769\n",
      "Recall: 0.9772727272727273\n",
      "Specificity: 0.4375\n",
      "f2-Score: 0.8531746031746033\n",
      "\n",
      "\n",
      "[[14  8]\n",
      " [ 5 93]]\n",
      "Rodada: # 6\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9207920792079208\n",
      "Recall: 0.9489795918367347\n",
      "Specificity: 0.6363636363636364\n",
      "f2-Score: 0.9262948207171315\n",
      "\n",
      "\n",
      "[[24  7]\n",
      " [ 4 85]]\n",
      "Rodada: # 7\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9239130434782609\n",
      "Recall: 0.9550561797752809\n",
      "Specificity: 0.7741935483870968\n",
      "f2-Score: 0.9299781181619254\n",
      "\n",
      "\n",
      "[[19  8]\n",
      " [ 5 88]]\n",
      "Rodada: # 8\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9166666666666666\n",
      "Recall: 0.946236559139785\n",
      "Specificity: 0.7037037037037037\n",
      "f2-Score: 0.9224318658280922\n",
      "\n",
      "\n",
      "[[25  4]\n",
      " [ 5 86]]\n",
      "Rodada: # 9\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.925\n",
      "Precision: 0.9555555555555556\n",
      "Recall: 0.945054945054945\n",
      "Specificity: 0.8620689655172413\n",
      "f2-Score: 0.9534368070953436\n",
      "\n",
      "\n",
      "[[17 10]\n",
      " [10 83]]\n",
      "Rodada: # 10\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8333333333333334\n",
      "Precision: 0.8924731182795699\n",
      "Recall: 0.8924731182795699\n",
      "Specificity: 0.6296296296296297\n",
      "f2-Score: 0.89247311827957\n",
      "\n",
      "\n",
      "[[20 11]\n",
      " [ 3 86]]\n",
      "Rodada: # 11\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8865979381443299\n",
      "Recall: 0.9662921348314607\n",
      "Specificity: 0.6451612903225806\n",
      "f2-Score: 0.9014675052410901\n",
      "\n",
      "\n",
      "[[25 11]\n",
      " [ 6 78]]\n",
      "Rodada: # 12\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8583333333333333\n",
      "Precision: 0.8764044943820225\n",
      "Recall: 0.9285714285714286\n",
      "Specificity: 0.6944444444444444\n",
      "f2-Score: 0.8863636363636365\n",
      "\n",
      "\n",
      "[[24  9]\n",
      " [ 5 82]]\n",
      "Rodada: # 13\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9010989010989011\n",
      "Recall: 0.9425287356321839\n",
      "Specificity: 0.7272727272727273\n",
      "f2-Score: 0.909090909090909\n",
      "\n",
      "\n",
      "[[22  7]\n",
      " [ 1 90]]\n",
      "Rodada: # 14\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9278350515463918\n",
      "Recall: 0.989010989010989\n",
      "Specificity: 0.7586206896551724\n",
      "f2-Score: 0.9394572025052192\n",
      "\n",
      "\n",
      "[[28  7]\n",
      " [ 2 83]]\n",
      "Rodada: # 15\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.925\n",
      "Precision: 0.9222222222222223\n",
      "Recall: 0.9764705882352941\n",
      "Specificity: 0.8\n",
      "f2-Score: 0.9325842696629214\n",
      "\n",
      "\n",
      "[[24  7]\n",
      " [ 5 84]]\n",
      "Rodada: # 16\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.9438202247191011\n",
      "Specificity: 0.7741935483870968\n",
      "f2-Score: 0.9271523178807949\n",
      "\n",
      "\n",
      "[[21 12]\n",
      " [ 2 85]]\n",
      "Rodada: # 17\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8762886597938144\n",
      "Recall: 0.9770114942528736\n",
      "Specificity: 0.6363636363636364\n",
      "f2-Score: 0.8947368421052633\n",
      "\n",
      "\n",
      "[[18 10]\n",
      " [ 1 91]]\n",
      "Rodada: # 18\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.900990099009901\n",
      "Recall: 0.9891304347826086\n",
      "Specificity: 0.6428571428571429\n",
      "f2-Score: 0.9173387096774194\n",
      "\n",
      "\n",
      "[[31  4]\n",
      " [ 9 76]]\n",
      "Rodada: # 19\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.95\n",
      "Recall: 0.8941176470588236\n",
      "Specificity: 0.8857142857142857\n",
      "f2-Score: 0.9382716049382717\n",
      "\n",
      "\n",
      "[[22  2]\n",
      " [10 86]]\n",
      "Rodada: # 20\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9772727272727273\n",
      "Recall: 0.8958333333333334\n",
      "Specificity: 0.9166666666666666\n",
      "f2-Score: 0.9598214285714285\n",
      "\n",
      "\n",
      "[[20  9]\n",
      " [ 7 84]]\n",
      "Rodada: # 21\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.9032258064516129\n",
      "Recall: 0.9230769230769231\n",
      "Specificity: 0.6896551724137931\n",
      "f2-Score: 0.9071274298056156\n",
      "\n",
      "\n",
      "[[14  4]\n",
      " [ 8 94]]\n",
      "Rodada: # 22\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9591836734693877\n",
      "Recall: 0.9215686274509803\n",
      "Specificity: 0.7777777777777778\n",
      "f2-Score: 0.951417004048583\n",
      "\n",
      "\n",
      "[[23 10]\n",
      " [ 5 82]]\n",
      "Rodada: # 23\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.8913043478260869\n",
      "Recall: 0.9425287356321839\n",
      "Specificity: 0.696969696969697\n",
      "f2-Score: 0.9010989010989011\n",
      "\n",
      "\n",
      "[[23 15]\n",
      " [ 2 80]]\n",
      "Rodada: # 24\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8583333333333333\n",
      "Precision: 0.8421052631578947\n",
      "Recall: 0.975609756097561\n",
      "Specificity: 0.6052631578947368\n",
      "f2-Score: 0.8658008658008658\n",
      "\n",
      "\n",
      "[[22  7]\n",
      " [ 7 84]]\n",
      "Rodada: # 25\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.9230769230769231\n",
      "Specificity: 0.7586206896551724\n",
      "f2-Score: 0.9230769230769231\n",
      "\n",
      "\n",
      "[[19  7]\n",
      " [ 7 87]]\n",
      "Rodada: # 26\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.925531914893617\n",
      "Recall: 0.925531914893617\n",
      "Specificity: 0.7307692307692307\n",
      "f2-Score: 0.9255319148936171\n",
      "\n",
      "\n",
      "[[22 10]\n",
      " [ 6 82]]\n",
      "Rodada: # 27\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8913043478260869\n",
      "Recall: 0.9318181818181818\n",
      "Specificity: 0.6875\n",
      "f2-Score: 0.8991228070175437\n",
      "\n",
      "\n",
      "[[22  3]\n",
      " [ 4 91]]\n",
      "Rodada: # 28\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9416666666666667\n",
      "Precision: 0.9680851063829787\n",
      "Recall: 0.9578947368421052\n",
      "Specificity: 0.88\n",
      "f2-Score: 0.9660297239915075\n",
      "\n",
      "\n",
      "[[24 10]\n",
      " [ 5 81]]\n",
      "Rodada: # 29\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.8901098901098901\n",
      "Recall: 0.9418604651162791\n",
      "Specificity: 0.7058823529411765\n",
      "f2-Score: 0.9\n",
      "\n",
      "\n",
      "[[20 10]\n",
      " [ 1 89]]\n",
      "Rodada: # 30\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.898989898989899\n",
      "Recall: 0.9888888888888889\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.9156378600823045\n",
      "\n",
      "\n",
      "[[20  8]\n",
      " [ 5 87]]\n",
      "Rodada: # 31\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9157894736842105\n",
      "Recall: 0.9456521739130435\n",
      "Specificity: 0.7142857142857143\n",
      "f2-Score: 0.9216101694915253\n",
      "\n",
      "\n",
      "[[25  3]\n",
      " [ 7 85]]\n",
      "Rodada: # 32\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9659090909090909\n",
      "Recall: 0.9239130434782609\n",
      "Specificity: 0.8928571428571429\n",
      "f2-Score: 0.9572072072072071\n",
      "\n",
      "\n",
      "[[30  8]\n",
      " [ 7 75]]\n",
      "Rodada: # 33\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.9036144578313253\n",
      "Recall: 0.9146341463414634\n",
      "Specificity: 0.7894736842105263\n",
      "f2-Score: 0.9057971014492754\n",
      "\n",
      "\n",
      "[[25  5]\n",
      " [ 3 87]]\n",
      "Rodada: # 34\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9456521739130435\n",
      "Recall: 0.9666666666666667\n",
      "Specificity: 0.8333333333333334\n",
      "f2-Score: 0.9497816593886462\n",
      "\n",
      "\n",
      "[[18  9]\n",
      " [ 3 90]]\n",
      "Rodada: # 35\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9090909090909091\n",
      "Recall: 0.967741935483871\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.920245398773006\n",
      "\n",
      "\n",
      "[[20  8]\n",
      " [ 2 90]]\n",
      "Rodada: # 36\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9183673469387755\n",
      "Recall: 0.9782608695652174\n",
      "Specificity: 0.7142857142857143\n",
      "f2-Score: 0.9297520661157024\n",
      "\n",
      "\n",
      "[[23  4]\n",
      " [ 8 85]]\n",
      "Rodada: # 37\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9550561797752809\n",
      "Recall: 0.9139784946236559\n",
      "Specificity: 0.8518518518518519\n",
      "f2-Score: 0.9465478841870822\n",
      "\n",
      "\n",
      "[[22  9]\n",
      " [ 3 86]]\n",
      "Rodada: # 38\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9052631578947369\n",
      "Recall: 0.9662921348314607\n",
      "Specificity: 0.7096774193548387\n",
      "f2-Score: 0.9168443496801706\n",
      "\n",
      "\n",
      "[[23  3]\n",
      " [ 4 90]]\n",
      "Rodada: # 39\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9416666666666667\n",
      "Precision: 0.967741935483871\n",
      "Recall: 0.9574468085106383\n",
      "Specificity: 0.8846153846153846\n",
      "f2-Score: 0.9656652360515022\n",
      "\n",
      "\n",
      "[[25  6]\n",
      " [ 9 80]]\n",
      "Rodada: # 40\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.9302325581395349\n",
      "Recall: 0.898876404494382\n",
      "Specificity: 0.8064516129032258\n",
      "f2-Score: 0.9237875288683602\n",
      "\n",
      "\n",
      "[[23  9]\n",
      " [ 5 83]]\n",
      "Rodada: # 41\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9021739130434783\n",
      "Recall: 0.9431818181818182\n",
      "Specificity: 0.71875\n",
      "f2-Score: 0.9100877192982457\n",
      "\n",
      "\n",
      "[[21  9]\n",
      " [ 2 88]]\n",
      "Rodada: # 42\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9072164948453608\n",
      "Recall: 0.9777777777777777\n",
      "Specificity: 0.7\n",
      "f2-Score: 0.9205020920502093\n",
      "\n",
      "\n",
      "[[17  8]\n",
      " [ 4 91]]\n",
      "Rodada: # 43\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9191919191919192\n",
      "Recall: 0.9578947368421052\n",
      "Specificity: 0.68\n",
      "f2-Score: 0.9266802443991854\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 11]\n",
      " [ 4 83]]\n",
      "Rodada: # 44\n",
      "{'alpha': 1}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.8829787234042553\n",
      "Recall: 0.9540229885057471\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.896328293736501\n",
      "\n",
      "\n",
      "[[18 15]\n",
      " [ 1 86]]\n",
      "Rodada: # 45\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8514851485148515\n",
      "Recall: 0.9885057471264368\n",
      "Specificity: 0.5454545454545454\n",
      "f2-Score: 0.875763747454175\n",
      "\n",
      "\n",
      "[[17  8]\n",
      " [ 5 90]]\n",
      "Rodada: # 46\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9183673469387755\n",
      "Recall: 0.9473684210526315\n",
      "Specificity: 0.68\n",
      "f2-Score: 0.9240246406570841\n",
      "\n",
      "\n",
      "[[15  9]\n",
      " [ 3 93]]\n",
      "Rodada: # 47\n",
      "{'alpha': 0.01}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9117647058823529\n",
      "Recall: 0.96875\n",
      "Specificity: 0.625\n",
      "f2-Score: 0.9226190476190474\n",
      "\n",
      "\n",
      "[[21 10]\n",
      " [ 2 87]]\n",
      "Rodada: # 48\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8969072164948454\n",
      "Recall: 0.9775280898876404\n",
      "Specificity: 0.6774193548387096\n",
      "f2-Score: 0.9119496855345911\n",
      "\n",
      "\n",
      "[[25  9]\n",
      " [ 3 83]]\n",
      "Rodada: # 49\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9021739130434783\n",
      "Recall: 0.9651162790697675\n",
      "Specificity: 0.7352941176470589\n",
      "f2-Score: 0.9140969162995596\n",
      "\n",
      "\n",
      "============================================== REGRESSÃO LOGÍSTICA =================================================\n",
      "=================================== TABELA DE MÉTRICAS DO MODELO ===================================\n",
      "\t Accuracy \t|\t Precision \t|\t Recall \t|\tSpecificity \t|\t fb-Score\n",
      "      0.89 +- 0.03             0.91 +- 0.03          0.95 +- 0.03             0.73 +- 0.10             0.92 +- 0.03\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#DEFININDO OS PARÂMETROS\n",
    "max_iter = 6000\n",
    "epocas = 50\n",
    "k_folds = 5\n",
    "exibir_matriz_confusao = True\n",
    "exibir_metricas = True\n",
    "\n",
    "# TREINANDO O MODELO E OBTENDO AS MÉTRICAS\n",
    "\n",
    "dict_metricas = treinamento_teste(epocas, k_folds, exibir_matriz_confusao, exibir_metricas)\n",
    "tabelaMetricas('REGRESSÃO LOGÍSTICA',dict_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
