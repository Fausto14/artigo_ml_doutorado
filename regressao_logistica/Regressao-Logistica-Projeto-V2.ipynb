{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTAR BIBLIOTECAS UTILIZADAS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Classe para processar o dataset\n",
    "    Obs: o dataset tem que ser para problemas de classificacao e nele tem que conter uma coluna Class\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../Util'))\n",
    "from dados import ProcessarDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANDO DATASET\n",
    "\n",
    "dataset = ProcessarDados('../dataset/norm_bin_10_FEATURES_M17_CM6b_TH199.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que treina e testa o modelo armazenando as métricas\n",
    "# retorna um dicionário cotendo os valores das métricas de cada rodada\n",
    "\n",
    "def treinamento_teste(epocas = 10, k_folds = 5, exibir_matriz_confusao=False, exibir_metricas=False):\n",
    "    \n",
    "    #array para armazenar as das métricas de cada rodada\n",
    "    resultados_accuracy = []\n",
    "    resultados_precision = []\n",
    "    resultados_recall = []\n",
    "    resultados_specificity = [] # taxa de verdadeiros negativos ou especificidade\n",
    "    resultados_f2 = []\n",
    "    resultados_parametros = []\n",
    "    \n",
    "    #dicionário das métricas\n",
    "    resultados_gerais = {}\n",
    "\n",
    "    for i in range(epocas):\n",
    "        #SEPARAR DADOS DE TREINO E TESTE MANTENDO A MESMA PROPORÇÃO  (80% E 20%)\n",
    "        seed = i\n",
    "        X_treino, X_teste, y_treino, y_teste = dataset.holdout(0.2, seed)\n",
    "        \n",
    "        #ALTERANDO DIMENSÃO DE Y PARA D=1\n",
    "\n",
    "        y_treino = y_treino.reshape(480,)\n",
    "        y_teste = y_teste.reshape(120,)\n",
    "        \n",
    "        # realizando o grid search para encontrar o melhor alpha, \n",
    "        # considerando a acurácia (taxa de acerto)\n",
    "        # aqui o método GridSearchCV é configurado para subdividir os dados de treino em k_folds\n",
    "        rl = LogisticRegression(random_state = seed)\n",
    "        grid_rl = GridSearchCV(rl, param_grid, cv=k_folds, scoring='accuracy', verbose=0)\n",
    "        grid_rl.fit(X_treino, y_treino)\n",
    "\n",
    "        # Treinando do modelo com os melhores parametros encontrados\n",
    "        alpha_best = grid_rl.best_estimator_.tol\n",
    "\n",
    "        rl = LogisticRegression(random_state = seed, tol = alpha_best)\n",
    "        rl.fit(X_treino, y_treino)\n",
    "\n",
    "        #testando o modelo\n",
    "        y_pred = rl.predict(X_teste)\n",
    "        \n",
    "        cm  = confusion_matrix(y_teste, y_pred)\n",
    "        if exibir_matriz_confusao:\n",
    "            print(cm)\n",
    "\n",
    "\n",
    "        # calculado as metricas\n",
    "        accuracy = metrics.accuracy_score(y_teste, y_pred)\n",
    "        precision = metrics.precision_score(y_teste, y_pred)\n",
    "        recall = metrics.recall_score(y_teste, y_pred)\n",
    "        # f2-score\n",
    "        # Fbeta = ((1 + beta^2) * Precision * Recall) / (beta^2 * Precision + Recall)\n",
    "        beta = 0.5\n",
    "        f2_score = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn+fp)\n",
    "        \n",
    "\n",
    "        # armazenando as métricas\n",
    "        resultados_accuracy.append(accuracy)\n",
    "        resultados_precision.append(precision)\n",
    "        resultados_recall.append(recall)\n",
    "        resultados_specificity.append(specificity)\n",
    "        resultados_f2.append(f2_score)\n",
    "\n",
    "        best_parametros = {'alpha' : alpha_best};\n",
    "        resultados_parametros.append(best_parametros)\n",
    "        \n",
    "        if exibir_metricas:\n",
    "            print(\"Rodada: #\",i)\n",
    "            print(best_parametros)\n",
    "            print(\"Accuracy:\",accuracy)\n",
    "            print(\"Precision:\",precision)\n",
    "            print(\"Recall:\",recall)\n",
    "            print(\"Specificity:\",specificity)\n",
    "            print(\"f2-Score:\",f2_score)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            \n",
    "    resultados_gerais['accuracy'] = resultados_accuracy\n",
    "    resultados_gerais['precision'] = resultados_precision\n",
    "    resultados_gerais['recall'] = resultados_recall\n",
    "    resultados_gerais['specificity'] = resultados_specificity\n",
    "    resultados_gerais['f2'] = resultados_f2\n",
    "    resultados_gerais['params'] = resultados_parametros\n",
    "    \n",
    "    return resultados_gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabelaMetricas(nome_modelo, dict_metricas, rodadas=False, salvarResultados=True):\n",
    "        \n",
    "    print (\"============================================== \"+nome_modelo+\" =================================================\")\n",
    "    print (\"=================================== TABELA DE MÉTRICAS DO MODELO ===================================\")\n",
    "    \n",
    "    if(rodadas==False):\n",
    "        print (\"\\t Accuracy \\t|\\t Precision \\t|\\t Recall \\t|\\tSpecificity \\t|\\t fb-Score\")\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['accuracy'], axis=0), np.std(dict_metricas['accuracy'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['precision'], axis=0), np.std(dict_metricas['precision'], axis=0)),end='    ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['recall'], axis=0), np.std(dict_metricas['recall'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['specificity'], axis=0), np.std(dict_metricas['specificity'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['f2'], axis=0), np.std(dict_metricas['f2'], axis=0)))\n",
    "        print (\"====================================================================================================\")\n",
    "        \n",
    "    if(salvarResultados):\n",
    "        # save to npy file\n",
    "        np.save('../resultados/resultados_'+nome_modelo+'.npy', dict_metricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada: # 0\n",
      "{'alpha': 0.1333521432163324}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9468085106382979\n",
      "Recall: 0.967391304347826\n",
      "Specificity: 0.8214285714285714\n",
      "f2-Score: 0.9508547008547008\n",
      "\n",
      "\n",
      "Rodada: # 1\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.865979381443299\n",
      "Recall: 0.9655172413793104\n",
      "Specificity: 0.6060606060606061\n",
      "f2-Score: 0.8842105263157896\n",
      "\n",
      "\n",
      "Rodada: # 2\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.9285714285714286\n",
      "Specificity: 0.6818181818181818\n",
      "f2-Score: 0.9285714285714286\n",
      "\n",
      "\n",
      "Rodada: # 3\n",
      "{'alpha': 0.4216965034285822}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 0.9659090909090909\n",
      "Specificity: 0.6875\n",
      "f2-Score: 0.9081196581196581\n",
      "\n",
      "\n",
      "Rodada: # 4\n",
      "{'alpha': 0.31622776601683794}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9375\n",
      "Recall: 0.9782608695652174\n",
      "Specificity: 0.7857142857142857\n",
      "f2-Score: 0.9453781512605044\n",
      "\n",
      "\n",
      "Rodada: # 5\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.86\n",
      "Recall: 0.9772727272727273\n",
      "Specificity: 0.5625\n",
      "f2-Score: 0.8811475409836065\n",
      "\n",
      "\n",
      "Rodada: # 6\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.925\n",
      "Precision: 0.9587628865979382\n",
      "Recall: 0.9489795918367347\n",
      "Specificity: 0.8181818181818182\n",
      "f2-Score: 0.9567901234567903\n",
      "\n",
      "\n",
      "Rodada: # 7\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9239130434782609\n",
      "Recall: 0.9550561797752809\n",
      "Specificity: 0.7741935483870968\n",
      "f2-Score: 0.9299781181619254\n",
      "\n",
      "\n",
      "Rodada: # 8\n",
      "{'alpha': 0.4216965034285822}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9175257731958762\n",
      "Recall: 0.956989247311828\n",
      "Specificity: 0.7037037037037037\n",
      "f2-Score: 0.925155925155925\n",
      "\n",
      "\n",
      "Rodada: # 9\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9560439560439561\n",
      "Recall: 0.9560439560439561\n",
      "Specificity: 0.8620689655172413\n",
      "f2-Score: 0.9560439560439562\n",
      "\n",
      "\n",
      "Rodada: # 10\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.85\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 0.9139784946236559\n",
      "Specificity: 0.6296296296296297\n",
      "f2-Score: 0.8985200845665963\n",
      "\n",
      "\n",
      "Rodada: # 11\n",
      "{'alpha': 0.1778279410038923}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9042553191489362\n",
      "Recall: 0.9550561797752809\n",
      "Specificity: 0.7096774193548387\n",
      "f2-Score: 0.913978494623656\n",
      "\n",
      "\n",
      "Rodada: # 12\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8863636363636364\n",
      "Recall: 0.9285714285714286\n",
      "Specificity: 0.7222222222222222\n",
      "f2-Score: 0.8944954128440364\n",
      "\n",
      "\n",
      "Rodada: # 13\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8817204301075269\n",
      "Recall: 0.9425287356321839\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.8932461873638343\n",
      "\n",
      "\n",
      "Rodada: # 14\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9263157894736842\n",
      "Recall: 0.967032967032967\n",
      "Specificity: 0.7586206896551724\n",
      "f2-Score: 0.9341825902335457\n",
      "\n",
      "\n",
      "Rodada: # 15\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8842105263157894\n",
      "Recall: 0.9882352941176471\n",
      "Specificity: 0.6857142857142857\n",
      "f2-Score: 0.9032258064516129\n",
      "\n",
      "\n",
      "Rodada: # 16\n",
      "{'alpha': 0.23713737056616552}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9139784946236559\n",
      "Recall: 0.9550561797752809\n",
      "Specificity: 0.7419354838709677\n",
      "f2-Score: 0.9219088937093275\n",
      "\n",
      "\n",
      "Rodada: # 17\n",
      "{'alpha': 0.7498942093324559}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9032258064516129\n",
      "Recall: 0.9655172413793104\n",
      "Specificity: 0.7272727272727273\n",
      "f2-Score: 0.9150326797385622\n",
      "\n",
      "\n",
      "Rodada: # 18\n",
      "{'alpha': 0.4216965034285822}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8921568627450981\n",
      "Recall: 0.9891304347826086\n",
      "Specificity: 0.6071428571428571\n",
      "f2-Score: 0.9099999999999999\n",
      "\n",
      "\n",
      "Rodada: # 19\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9512195121951219\n",
      "Recall: 0.9176470588235294\n",
      "Specificity: 0.8857142857142857\n",
      "f2-Score: 0.9443099273607749\n",
      "\n",
      "\n",
      "Rodada: # 20\n",
      "{'alpha': 1.0}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9456521739130435\n",
      "Recall: 0.90625\n",
      "Specificity: 0.7916666666666666\n",
      "f2-Score: 0.9375000000000001\n",
      "\n",
      "\n",
      "Rodada: # 21\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8416666666666667\n",
      "Precision: 0.875\n",
      "Recall: 0.9230769230769231\n",
      "Specificity: 0.5862068965517241\n",
      "f2-Score: 0.8842105263157894\n",
      "\n",
      "\n",
      "Rodada: # 22\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.96\n",
      "Recall: 0.9411764705882353\n",
      "Specificity: 0.7777777777777778\n",
      "f2-Score: 0.9561752988047809\n",
      "\n",
      "\n",
      "Rodada: # 23\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8924731182795699\n",
      "Recall: 0.9540229885057471\n",
      "Specificity: 0.696969696969697\n",
      "f2-Score: 0.9041394335511983\n",
      "\n",
      "\n",
      "Rodada: # 24\n",
      "{'alpha': 0.0031622776601683794}\n",
      "Accuracy: 0.8583333333333333\n",
      "Precision: 0.8350515463917526\n",
      "Recall: 0.9878048780487805\n",
      "Specificity: 0.5789473684210527\n",
      "f2-Score: 0.8617021276595745\n",
      "\n",
      "\n",
      "Rodada: # 25\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.925531914893617\n",
      "Recall: 0.9560439560439561\n",
      "Specificity: 0.7586206896551724\n",
      "f2-Score: 0.9314775160599573\n",
      "\n",
      "\n",
      "Rodada: # 26\n",
      "{'alpha': 1.0}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.9354838709677419\n",
      "Recall: 0.925531914893617\n",
      "Specificity: 0.7692307692307693\n",
      "f2-Score: 0.9334763948497852\n",
      "\n",
      "\n",
      "Rodada: # 27\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8583333333333333\n",
      "Precision: 0.8817204301075269\n",
      "Recall: 0.9318181818181818\n",
      "Specificity: 0.65625\n",
      "f2-Score: 0.8913043478260869\n",
      "\n",
      "\n",
      "Rodada: # 28\n",
      "{'alpha': 0.1}\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.967741935483871\n",
      "Recall: 0.9473684210526315\n",
      "Specificity: 0.88\n",
      "f2-Score: 0.9635974304068522\n",
      "\n",
      "\n",
      "Rodada: # 29\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.9\n",
      "Recall: 0.9418604651162791\n",
      "Specificity: 0.7352941176470589\n",
      "f2-Score: 0.9080717488789237\n",
      "\n",
      "\n",
      "Rodada: # 30\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8979591836734694\n",
      "Recall: 0.9777777777777777\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.9128630705394192\n",
      "\n",
      "\n",
      "Rodada: # 31\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8916666666666667\n",
      "Precision: 0.898989898989899\n",
      "Recall: 0.967391304347826\n",
      "Specificity: 0.6428571428571429\n",
      "f2-Score: 0.9118852459016394\n",
      "\n",
      "\n",
      "Rodada: # 32\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.925\n",
      "Precision: 0.9560439560439561\n",
      "Recall: 0.9456521739130435\n",
      "Specificity: 0.8571428571428571\n",
      "f2-Score: 0.9539473684210527\n",
      "\n",
      "\n",
      "Rodada: # 33\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8953488372093024\n",
      "Recall: 0.9390243902439024\n",
      "Specificity: 0.7631578947368421\n",
      "f2-Score: 0.903755868544601\n",
      "\n",
      "\n",
      "Rodada: # 34\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.925531914893617\n",
      "Recall: 0.9666666666666667\n",
      "Specificity: 0.7666666666666667\n",
      "f2-Score: 0.9334763948497855\n",
      "\n",
      "\n",
      "Rodada: # 35\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.8979591836734694\n",
      "Recall: 0.946236559139785\n",
      "Specificity: 0.6296296296296297\n",
      "f2-Score: 0.9072164948453607\n",
      "\n",
      "\n",
      "Rodada: # 36\n",
      "{'alpha': 0.7498942093324559}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.9183673469387755\n",
      "Recall: 0.9782608695652174\n",
      "Specificity: 0.7142857142857143\n",
      "f2-Score: 0.9297520661157024\n",
      "\n",
      "\n",
      "Rodada: # 37\n",
      "{'alpha': 0.7498942093324559}\n",
      "Accuracy: 0.9083333333333333\n",
      "Precision: 0.9555555555555556\n",
      "Recall: 0.9247311827956989\n",
      "Specificity: 0.8518518518518519\n",
      "f2-Score: 0.9492273730684327\n",
      "\n",
      "\n",
      "Rodada: # 38\n",
      "{'alpha': 0.4216965034285822}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9052631578947369\n",
      "Recall: 0.9662921348314607\n",
      "Specificity: 0.7096774193548387\n",
      "f2-Score: 0.9168443496801706\n",
      "\n",
      "\n",
      "Rodada: # 39\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9416666666666667\n",
      "Precision: 0.978021978021978\n",
      "Recall: 0.9468085106382979\n",
      "Specificity: 0.9230769230769231\n",
      "f2-Score: 0.9716157205240176\n",
      "\n",
      "\n",
      "Rodada: # 40\n",
      "{'alpha': 0.5623413251903491}\n",
      "Accuracy: 0.875\n",
      "Precision: 0.9204545454545454\n",
      "Recall: 0.9101123595505618\n",
      "Specificity: 0.7741935483870968\n",
      "f2-Score: 0.9183673469387754\n",
      "\n",
      "\n",
      "Rodada: # 41\n",
      "{'alpha': 0.1778279410038923}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9042553191489362\n",
      "Recall: 0.9659090909090909\n",
      "Specificity: 0.71875\n",
      "f2-Score: 0.915948275862069\n",
      "\n",
      "\n",
      "Rodada: # 42\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8979591836734694\n",
      "Recall: 0.9777777777777777\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.9128630705394192\n",
      "\n",
      "\n",
      "Rodada: # 43\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9278350515463918\n",
      "Recall: 0.9473684210526315\n",
      "Specificity: 0.72\n",
      "f2-Score: 0.9316770186335405\n",
      "\n",
      "\n",
      "Rodada: # 44\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.8666666666666667\n",
      "Precision: 0.8736842105263158\n",
      "Recall: 0.9540229885057471\n",
      "Specificity: 0.6363636363636364\n",
      "f2-Score: 0.8886509635974303\n",
      "\n",
      "\n",
      "Rodada: # 45\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.85\n",
      "Precision: 0.8415841584158416\n",
      "Recall: 0.9770114942528736\n",
      "Specificity: 0.5151515151515151\n",
      "f2-Score: 0.865580448065173\n",
      "\n",
      "\n",
      "Rodada: # 46\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 0.956989247311828\n",
      "Recall: 0.9368421052631579\n",
      "Specificity: 0.84\n",
      "f2-Score: 0.9528907922912205\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodada: # 47\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.92\n",
      "Recall: 0.9583333333333334\n",
      "Specificity: 0.6666666666666666\n",
      "f2-Score: 0.9274193548387095\n",
      "\n",
      "\n",
      "Rodada: # 48\n",
      "{'alpha': 0.001}\n",
      "Accuracy: 0.9\n",
      "Precision: 0.8888888888888888\n",
      "Recall: 0.9887640449438202\n",
      "Specificity: 0.6451612903225806\n",
      "f2-Score: 0.9072164948453609\n",
      "\n",
      "\n",
      "Rodada: # 49\n",
      "{'alpha': 0.23713737056616552}\n",
      "Accuracy: 0.8833333333333333\n",
      "Precision: 0.8829787234042553\n",
      "Recall: 0.9651162790697675\n",
      "Specificity: 0.6764705882352942\n",
      "f2-Score: 0.8982683982683982\n",
      "\n",
      "\n",
      "============================================== RL =================================================\n",
      "=================================== TABELA DE MÉTRICAS DO MODELO ===================================\n",
      "\t Accuracy \t|\t Precision \t|\t Recall \t|\tSpecificity \t|\t fb-Score\n",
      "      0.90 +- 0.02             0.91 +- 0.03          0.95 +- 0.02             0.72 +- 0.09             0.92 +- 0.03\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#DEFININDO OS PARÂMETROS\n",
    "\n",
    "\n",
    "alpha_range = np.logspace(-3,0,25)\n",
    "param_grid = {'tol': alpha_range}\n",
    "\n",
    "epocas = 50\n",
    "k_folds = 5\n",
    "exibir_matriz_confusao = False\n",
    "exibir_metricas = True\n",
    "\n",
    "# TREINANDO O MODELO E OBTENDO AS MÉTRICAS\n",
    "\n",
    "dict_metricas = treinamento_teste(epocas, k_folds, exibir_matriz_confusao, exibir_metricas)\n",
    "tabelaMetricas('RL',dict_metricas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
