{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../Util'))\n",
    "from dados import ProcessarDados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "procData = ProcessarDados(\"../dataset/norm_bin_10_FEATURES_M17_CM6b_TH199.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcção que treina e testa o modelo armazenando as métricas\n",
    "# retorna um dicionário cotendo os valores das métricas de cada rodada\n",
    "def treinamento_teste(epocas = 10, k_folds = 5, exibir_matriz_confusao=False, exibir_metricas=False):\n",
    "    \n",
    "    #array para armazenar as das métricas de cada rodada\n",
    "    resultados_accuracy = []\n",
    "    resultados_precision = []\n",
    "    resultados_recall = []\n",
    "    resultados_f1 = []\n",
    "    resultados_parametros = []\n",
    "    \n",
    "    #dicionário das métricas\n",
    "    resultados_gerais = {}\n",
    "\n",
    "    for i in range(epocas):\n",
    "        # divisão os dados \n",
    "        X_train, X_test, y_train, y_test = procData.holdout(0.2)\n",
    "        #print(Counter(y_test))\n",
    "\n",
    "        # realizando o grid search para encontrar a melhor K-Vizinhos, \n",
    "        # considerando a acurácia (taxa de acerto)\n",
    "        # aqui o método GridSearchCV é configurado para subdividir os dados de treino em k_folds\n",
    "        clf = KNeighborsClassifier()\n",
    "        grid_knn = GridSearchCV(clf, param_grid, cv=k_folds, scoring='accuracy', verbose=0, n_jobs=-1)\n",
    "        grid_knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Treinando do modelo com os melhores parametros encontrados\n",
    "        grid_knn.best_params_\n",
    "        Kvizinhos_best = int(grid_knn.best_params_['n_neighbors']) \n",
    "        distancia_best = grid_knn.best_estimator_.weights\n",
    "        KNN = KNeighborsClassifier(n_neighbors=Kvizinhos_best, weights=distancia_best, metric='minkowski', p = 2)\n",
    "        KNN.fit(X_train, y_train)\n",
    "\n",
    "        #testando o modelo\n",
    "        y_pred = KNN.predict(X_test)\n",
    "        if exibir_matriz_confusao:\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        # calculado as metricas\n",
    "        accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        # armazenando as métricas\n",
    "        resultados_accuracy.append(accuracy)\n",
    "        resultados_precision.append(precision)\n",
    "        resultados_recall.append(recall)\n",
    "        resultados_f1.append(f1_score)\n",
    "\n",
    "        best_parametros = \"K-Vizinhos(n_neighbors): \"+ str(Kvizinhos_best)+ \" | Distância(weights): \"+distancia_best;\n",
    "        resultados_parametros.append(best_parametros)\n",
    "\n",
    "\n",
    "        if exibir_metricas:\n",
    "            print(\"Rodada: #\",i)\n",
    "            print(best_parametros)\n",
    "            print(\"Accuracy:\",accuracy)\n",
    "            print(\"Precision:\",precision)\n",
    "            print(\"Recall:\",recall)\n",
    "            print(\"F1-Score:\",f1_score)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            \n",
    "    resultados_gerais['accuracy'] = resultados_accuracy\n",
    "    resultados_gerais['precision'] = resultados_precision\n",
    "    resultados_gerais['recall'] = resultados_recall\n",
    "    resultados_gerais['f1'] = resultados_f1\n",
    "    \n",
    "    return resultados_gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabelaMetricas(nome_modelo, dict_metricas, rodadas=False, salvarResultados=True):\n",
    "    print (\"============================================== \"+nome_modelo+\" =================================================\")\n",
    "    print (\"=================================== TABELA DE MÉTRICAS DO MODELO ===================================\")\n",
    "    \n",
    "    if(rodadas==False):\n",
    "        print (\"\\t Accuracy \\t|\\t Precision \\t|\\t Recall \\t|\\t F1-Score\")\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['accuracy'], axis=0), np.std(dict_metricas['accuracy'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['precision'], axis=0), np.std(dict_metricas['precision'], axis=0)),end='    ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['recall'], axis=0), np.std(dict_metricas['recall'], axis=0)),end='       ')\n",
    "        print (\"      %.2f +- %.2f\" % (np.mean(dict_metricas['f1'], axis=0), np.std(dict_metricas['f1'], axis=0)))\n",
    "        print (\"====================================================================================================\")\n",
    "        \n",
    "    if(salvarResultados):\n",
    "        # save to npy file\n",
    "        np.save('../resultados/resultados_'+nome_modelo+'.npy', dict_metricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo os parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Vizinhos\n",
    "c_range = np.arange(1,25)\n",
    "#'uniforme': Todos os pontos em cada vizinho têm o mesmo peso.\n",
    "#'distância': Inverso de sua distância, os vizinhos mais próximos de um ponto de consulta terão uma influência maior do que os vizinhos mais distantes.\n",
    "distancia = ['uniform', 'distance'] \n",
    "param_grid = {'n_neighbors': c_range, 'weights':distancia}\n",
    "epocas = 50\n",
    "k_folds = 5\n",
    "exibir_matriz_confusao = True\n",
    "exibir_metricas = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando e obtendo as métricas do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando o modelo\n",
    "dict_metricas = treinamento_teste(epocas, k_folds, exibir_matriz_confusao, exibir_metricas)\n",
    "tabelaMetricas('KNN',dict_metricas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
